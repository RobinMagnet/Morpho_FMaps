{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87f4143",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./pyFM/')\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import itertools\n",
    "import copy\n",
    "\n",
    "import utils\n",
    "import networkx as nx\n",
    "\n",
    "import pyFM.spectral as spectral\n",
    "from pyFM.mesh import TriMesh\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from pyFM.FMN import FMN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fcf25d2",
   "metadata": {},
   "source": [
    "# Log Information "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915c093a",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_maps_dir = None # PATH WHERE TO LOG INITIAL MAPS\n",
    "\n",
    "network_file = None # PATH WHERE TO LOG THE NETWORK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4312d91a",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Load Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c405adc",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "path_list = [] # List of path for all shapes \n",
    "meshlist = [TriMesh(path).process(k=110, intrinsic=True) for path in tqdm(path_list)]\n",
    "\n",
    "n_meshes = len(meshlist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c564d6",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Initial Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1b0398",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "n_chosen_pairs = 2500  # Number of pairs to select in the network\n",
    "k_init = 50  # Initial size of functional maps. We recommand around 20 but because of the double surface we need 50\n",
    "n_subsample = 3000 # Number of samples to use for initial maps\n",
    "\n",
    "print(f'{int(scipy.special.binom(n_meshes, 2)):d} possible pairs')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef386d55",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Samples initial pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2561ba0a",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We sample random pairs in our graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a452024",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "rng = np.random.default_rng()\n",
    "\n",
    "all_pairs = list(itertools.combinations(np.arange(n_meshes), 2))\n",
    "rng.shuffle(all_pairs)\n",
    "\n",
    "chosen_pairs = all_pairs[:n_chosen_pairs]\n",
    "\n",
    "G = nx.Graph()\n",
    "G.add_nodes_from(np.arange(n_meshes))\n",
    "G.add_edges_from(chosen_pairs)\n",
    "\n",
    "\n",
    "print(f'Is G connected ? {nx.is_connected(G)}')\n",
    "all_cliques= nx.enumerate_all_cliques(G)\n",
    "triad_cliques=[x for x in all_cliques if len(x)==3 ]\n",
    "print(f'G has {G.number_of_nodes()} nodes and {G.number_of_edges()} edges')\n",
    "print(f'G has {len(triad_cliques)} 3-cycles')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7737af",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Compute initial correspondence using rigid alignment and functional maps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dfc483f",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Extract a subset of vertices to work on for init "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba1f6a9",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "subsample_list = np.zeros((n_meshes, n_subsample), dtype=int)\n",
    "for i in tqdm(range(len(meshlist))):\n",
    "    subsample_list[i] = meshlist[i].extract_fps(n_subsample, geodesic=False, verbose=False)\n",
    "    \n",
    "utils.save_pickle(os.path.join(init_maps_dir, \"init_samples.p\"), subsample_list)\n",
    "\n",
    "# Else load the file\n",
    "utils.load_pickle(os.path.join(init_maps_dir, \"init_samples.p\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3259fc3",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Compute intial functional maps for all pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7804b801",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "maps_dict = {}\n",
    "\n",
    "for pair_ind, (i, j) in enumerate(tqdm(chosen_pairs)):\n",
    "    \n",
    "    map_file_21 = os.path.join(init_maps_dir, f'{j}_to_{i}')\n",
    "    map_file_12 = os.path.join(init_maps_dir, f'{i}_to_{j}')\n",
    "    \n",
    "    fps1 = subsample_list[i]\n",
    "    fps2 = subsample_list[j]\n",
    "    \n",
    "    if os.path.isfile(map_file_21):\n",
    "        p2p_21 = utils.load_ints(map_file_21) # (n2,)\n",
    "        p2p_12 = utils.load_ints(map_file_12) # (n1,)\n",
    "        \n",
    "    else:\n",
    "        mesh1 = copy.deepcopy(meshlist[i])\n",
    "        mesh2 = copy.deepcopy(meshlist[j])\n",
    "\n",
    "        # Get initial correspondences\n",
    "        p2p_21_init_sub = utils.knn_query_normals(mesh1.vertlist[fps1], mesh2.vertlist[fps2],\n",
    "                                                  mesh1.vertex_normals[fps1], mesh2.vertex_normals[fps2],\n",
    "                                                  k_base=20, n_jobs=20, verbose=False)\n",
    "        \n",
    "        # ICP Align the shape\n",
    "        _, R, t = utils.icp_align(mesh2.vertlist[fps2], mesh1.vertlist[fps1],\n",
    "                                  p2p_12=p2p_21_init_sub,\n",
    "                                  return_params=True, n_jobs=n_jobs, epsilon=1e-4, verbose=False)\n",
    "\n",
    "        mesh2.rotate(R);\n",
    "        mesh2.translate(t);\n",
    "        \n",
    "        # Get final correspondences\n",
    "        p2p_21 = utils.knn_query_normals(mesh1.vertlist[fps1], mesh2.vertlist[fps2],\n",
    "                                         mesh1.vertex_normals[fps1], mesh2.vertex_normals[fps2],\n",
    "                                         k_base=50, n_jobs=n_jobs)\n",
    "        \n",
    "        p2p_12 = utils.knn_query_normals(mesh2.vertlist[fps2], mesh1.vertlist[fps1],\n",
    "                                         mesh2.vertex_normals[fps2], mesh1.vertex_normals[fps1],\n",
    "                                         k_base=50, n_jobs=n_jobs)\n",
    "\n",
    "        utils.save_ints(map_file_21, p2p_21)\n",
    "        utils.save_ints(map_file_12, p2p_12)\n",
    "        \n",
    "    # Compute initial functional maps\n",
    "    FM_12 = spectral.mesh_p2p_to_FM(p2p_21, meshlist[i], meshlist[j], dims=k_init, subsample=(fps1, fps2))\n",
    "    FM_21 = spectral.mesh_p2p_to_FM(p2p_12, meshlist[j], meshlist[i], dims=k_init, subsample=(fps2, fps1))\n",
    "    maps_dict[(i,j)] = FM_12.copy();\n",
    "    maps_dict[(j,i)] = FM_21.copy();\n",
    "    \n",
    "print(f'{len(maps_dict.keys())} maps computed');\n",
    "\n",
    "\n",
    "utils.save_pickle(os.path.join(init_maps_dir, \"init_FM.p\"), maps_dict);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f36dfc5",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# maps_dict = utils.load_pickle(os.path.join(init_maps_dir, \"init_FM.p\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78469ff1",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Refine the initial maps "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c0a0a2",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Build the functional map network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1074f7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "network = FMN(meshlist, maps_dict=maps_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1f2f59",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# These values were copied you can delete them\n",
    "del meshlist\n",
    "del maps_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f08cbf",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Select samples to work with in the network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e718a69",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sub_size = 2000\n",
    "subsample_list = np.zeros((len(network.meshlist),sub_size), dtype=int)\n",
    "for i in tqdm(range(len(network.meshlist))):\n",
    "    subsample_list[i] = network.meshlist[i].extract_fps(sub_size, geodesic=False, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774a98b2",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Refine the network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872dfc93",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "czo_parameters = {\n",
    "    'nit': (110-k_init)//5,\n",
    "    'step': 5,\n",
    "    'cclb_ratio': .8,\n",
    "    'subsample': subsample_list,\n",
    "    'isometric': False,\n",
    "    'verbose': True,\n",
    "    'use_ANN': False,\n",
    "    'weight_type': 'iscm',\n",
    "    'n_jobs': 15,\n",
    "    'backend': 'gpu'\n",
    "}\n",
    "\n",
    "\n",
    "network.zoomout_refine(**czo_parameters)\n",
    "utils.save_pickle(network_file, network)\n",
    "network.compute_W(M=110)\n",
    "network.compute_CCLB(int(.8*network.M), verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386ba5b9",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Extract Template "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf89cc3",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "deviation_from_id_a = np.zeros(network.n_meshes)\n",
    "deviation_from_id_cr = np.zeros(network.n_meshes)\n",
    "for i in range(network.n_meshes):\n",
    "    CSD_a, CSD_c = network.get_CSD(i)\n",
    "    deviation_from_id_a[i] = np.linalg.norm(CSD_a - np.eye(CSD_a.shape[0]))\n",
    "    deviation_from_id_cr[i] = np.linalg.norm(np.sqrt(cclb_ev)[:,None] * (CSD_c - np.eye(CSD_c.shape[0]))) / np.sqrt(cclb_ev.sum())\n",
    "\n",
    "    \n",
    "deviation_from_id_cr.argmin(), deviation_from_id_cr.argmin()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49d0045",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Chose on of the two templates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2c01a6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "base_meshind = deviation_from_id_cr.argmin()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ce1fbf",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Build Deformation Fields "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea6d2fc",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "k_displacement = 100\n",
    "backend = 'gpu' # OR \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1afe5d5",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\n",
    "mesh1 = copy.deepcopy(network.meshlist[base_meshind]) # TriMesh(network.meshlist[base_meshind].path, area_normalize=True).process(k=k_displacement,verbose=True)\n",
    "LB_1 = network.get_LB(base_meshind, complete=True)  # (n_1',m)\n",
    "\n",
    "displacements = np.zeros((network.n_meshes, 3*mesh1.n_vertices))\n",
    "displacements_red = np.zeros((network.n_meshes, 3*k_displacement))\n",
    "\n",
    "for meshind2 in tqdm(range(network.n_meshes)):\n",
    "    if meshind2 == base_meshind:\n",
    "        continue\n",
    "    \n",
    "    mesh2 = copy.deepcopy(network.meshlist[meshind2])\n",
    "    LB_2 = network.get_LB(meshind2, complete=True)  # (n_2',m)\n",
    "    \n",
    "    p2p_czo_12 = pyFM.FMN.knn_query(torch.from_numpy(LB_2.astype(np.float32)).cuda(), torch.from_numpy(LB_1.astype(np.float32)).cuda(), backend=backend).cpu().numpy()\n",
    "    R, t = utils.rigid_alignment(mesh1.vertlist, mesh2.vertlist, p2p_12=p2p_czo_12,\n",
    "                                 return_params=True, return_deformed=False, weights=mesh1.vertex_areas)\n",
    "    \n",
    "    \n",
    "    mesh2 = TriMesh(mesh2.vertlist, mesh2.facelist)\n",
    "    mesh2.translate(-t)\n",
    "    mesh2.rotate(np.linalg.inv(R))\n",
    "    \n",
    "    tau_czo = mesh1.project(mesh2.vertlist[p2p_czo_12] - mesh1.vertlist, k=k_displacement)\n",
    "    \n",
    "    displacements[meshind2] = mesh1.decode(tau_czo).flatten()\n",
    "    displacements_red[meshind2] = tau_czo.flatten()\n",
    "print('');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942fc334",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Apply PCA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c57f99",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ace482",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "avg_disp = np.mean(displacements_red,axis=0)\n",
    "pca_d = PCA(n_components=50)\n",
    "emb_d_red = pca_d.fit_transform(displacements_red - avg_disp[None,:])\n",
    "\n",
    "plt.figure(dpi=150)\n",
    "plt.title('Explained variance ratio')\n",
    "plt.xlabel('Number of components')\n",
    "plt.ylabel('Explained variance (%)')\n",
    "plt.plot(np.arange(1+pca_d.n_components) , 100*np.cumsum(np.concatenate([[0],pca_d.explained_variance_ratio_])), marker=\".\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161f2b52",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Apply logistic regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2981c5ce",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "labels = [] # list of labels for each skulls\n",
    "labels = np.asarray(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82d5c1a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "reglin1 = LogisticRegression(penalty='none', fit_intercept=True, max_iter=1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
